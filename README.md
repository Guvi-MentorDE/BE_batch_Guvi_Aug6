# BE_batch_Guvi_Aug6
Python Class Notes.

Install SQL workbench: {for AUG 17 class}
Download from ->
https://dev.mysql.com/downloads/workbench/

Installation steps on YT video 

-> https://www.youtube.com/watch?v=u96rVINbAUI



mYSQL REFERENCE MANUAL : https://dev.mysql.com/doc/refman/8.0/en/join.html


Refer for books and documents:

https://drive.google.com/drive/folders/1qJnUbeXwjIIPSv8LuO7_g4Ofeaf5Qbjf


We shall be using GCP for practise of Hadoop , Hive and Spark. Since GCP is going to offer 25K credits for 90 days best amount existing cloud providers. 

Instructions for Creating Hadoop cluster:

1) Enable your Free trial account account. [login into console.google.cloud]

2) Enabe your Dataproc API & storage API service. 

3) go to Dataproc -> create cluster -> login via ssh 

4) start using linux , hadoop , hive , spark. 


Follow the video to setup google cloud cli:
-----------------------------------------------
https://www.youtube.com/watch?v=7mE-9E4D4Os



Handelling Source code from Git to Hadoop Cluser:
--------------------------------------------------

Since many people are facing issues with respect to spacing in project execution. We can avoid copy pasting going forward. 


1) login into dataproc cluster.
2) do cd ~
3) sudo apt install git-all   [run the command] -> once done -> verify using -> git --version command.
4) create some directory of your choice and run "git clone https://github.com/Guvi-MentorDE/BE_batch_Guvi_Aug6.git"

lets not copy past or move to google cloud bucket going forward unless its necessary. 

