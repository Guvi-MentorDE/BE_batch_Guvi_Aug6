spark Core:
-----------
Architecure
patitioning
pypsark program   [job (task, stages) = tranfromation + actions ]
    job1= tranformations + actions 
    job2= tranformations                            + tranformations            +   tranformations +    action 
          4 partitions                             same 4 partitions                same 4 partitions    
          (4 taks will be launched in executer)   (4 taks will be launched in executer)
          Stage 1                   --->            stage 2             ---> stage3 ->         + action 
    job3= tranformations + actions 
        = tranformations + tranformations    / this is not even a job. 
    job5= tranformations + actions 

    job5= job(tranformations + actions )+ action + action .... 

    job.....n= tranformations + actions 

memory mangement
spark UI. 

Spark Core:
-------------
1) Tranformations 
2) Actions 
3) File handelling using RDD 
4) Data Clensing 

Spark DF:
-----------
1) DF basics 
2) DF reader / Writer 
    - spark.read
    - spark.write
    - DSL queries 
    - Spark SQL 
    - Tranformations 
3) type of data handelling:
    - Structured 
    - semi structured 
    - unstructured
    - Hive data handelling. 

Spark Streaming:
---------------

1) Spark streaming.
    -socket 
    -file 
    -kafka 
2) Spark Structure streaming.
    -socket 
    -file 
    -kafka 


Spark Memory and resouce calculation:
--------------------------------------
1) determine no fo executers
2) diff between tiny vs fat vs banlanced executers. 
3) spark submission command
    - static 
    - dynamic 